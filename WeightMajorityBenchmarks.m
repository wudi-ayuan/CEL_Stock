%clear;
%% % Generated by Jinsung Yoon (8/11/2016)
% Hedge Bandit

%% 1. Data Input
%load('Data.mat');
raw_data=importdata('wdbc.data.txt');
norm=max(raw_data(:,3:end));
Input_Feature=zeros(size(raw_data(:,3:end)));
for i=1:size(Input_Feature,1),
Input_Feature(i,:)=raw_data(i,3:end)./norm;
end
Input_Label=raw_data(:,2);
% Input_Feature, Input_Label

%% 2. System Variable
% General Parameters
[T, Feature_No] = size(Input_Feature);      % Number of Instances
M = 10;       % Number of Local Learner
No_E=10;

% Algorithm Parameters
% For IUP
m_i = 2;    % Number of partition on each feature
d_i = Feature_No/M;     % Number of features assinged to each Local Learner
F_i = 2;        % Number of hypothesis

% Fixed Variable
alpha_fix = 2 * ( 1 + 2* log( 2 * abs(F_i) * (m_i)^(d_i) * T^(1.5) ) );

%% 3. Algorithm

%% 3.1 Assigned features for each expert without overlapping
Temp_Select=randperm(Feature_No);
for e = 1:M
    F(e,:) = Temp_Select(((Feature_No/M)*e-((Feature_No/M)-1)):((Feature_No/M)*e));
end

%% 3.2 Initialization
%% Create Basic Matrix
% For IUP
S_T = zeros(M,m_i,m_i,m_i,F_i);    % Sum of rewards for each partition
N_T = zeros(M,m_i,m_i,m_i,F_i);    % Number of patients in each partition
R_T = zeros(M,m_i,m_i,m_i,F_i);    % Sample mean of Rewards for each partition

% Prediction of each expert
y_hat = zeros(T,M);

% For Ensemble Learner
w = (1/(M))*ones(M,1);    % Weights of each experts
final_y = zeros(T,1);    % Ensemble Learner Estimation
final = zeros(T,1);    % Ensemble Learner prediction

w = ones(No_E,1)/No_E;

%% 3.3 Online Algorithm
for t = 1:T
    %% A. Uniform Partitioning
    for f = 1:Feature_No
        for j = 1:m_i
            if(Input_Feature(t,f) >= (j-1)/m_i) && (Input_Feature(t,f) < j/m_i)
                x(t,f) = j;
            elseif (Input_Feature(t,f) == 1)
                x(t,f) = m_i;
            end
        end
    end
    
    %% B. IUP Algorithm
    for e = 1:M
        Temp1(e,1) = N_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),1);
        Temp2(e,1) = R_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),1);
        Index(e,1) = Temp2(e,1) + sqrt(alpha_fix/Temp1(e,1));
        
        Temp1(e,2) = N_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),2);
        Temp2(e,2) = R_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),2);
        Index(e,2) = Temp2(e,2) + sqrt(alpha_fix/Temp1(e,2));
        
        if(Temp1(e,1) == 0)
            y_hat(t,e) = 1;
        elseif (Temp1(e,2) == 0)
            y_hat(t,e) = 2;
        else
            [Temp y_hat(t,e)] = max(Index(e,:));
        end
        % y_hat(t,e) is the action that each expert selects
        
        % Update (Update estimated reward of the partition)
        S_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),y_hat(t,e)) = S_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),y_hat(t,e)) + (y_hat(t,e)==Input_Label(t));
        N_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),y_hat(t,e)) = N_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),y_hat(t,e)) + 1;
        R_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),y_hat(t,e)) = S_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),y_hat(t,e))/N_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),y_hat(t,e));
    end
    
    
    %% Ensemble Learner Algorithm (Using Weighted Majority)
    %% (1). PWM
    % Weights for PWM
    %(A).Find the weighted sum of local learner decision
    WS_LL(t) = 0; % Initialization
    for e = 1:(No_E)
        % sum of each LL prediction
        WS_LL(t) = WS_LL(t) + w(e)*y_hat(t,e);
    end
    % (B). Decide Final Action
    if (WS_LL(t) >= 0)
        final(t) = 1;
    else
        final(t) = -1;
    end
    
    % (C). Update Weights
    % Only for the wrong prediction, we update the weights
    for e = 1:(No_E)
        w(e) = w(e) + Train_Label(t) * y_hat(t,e);
    end
    %% (2). Weighted Majority
    kau = 0.99;
    
    % (A).Weighted sum of each expert decision
    WS_LL(t) = 0;
    for e = 1:No_E
        WS_LL(t) = WS_LL(t) + (w(e)/sum(w)) * y_hat(t,e);
    end
    % (B). Decide The final action
    if (WS_LL(t) >= 0)
        final(t) = 1;   % Malignant
    else
        final(t) = -1;   % Benign
    end
    % (C). Update weights
    for e = 1:No_E
        % Update for every incorrect prediction
        if (y(t,e) ~= Train_Label(t))
            w(e) = w(e)*kau;    % Punish for Miss prediction
        end
    end
    % (D). Normalized w after updating
    sum_ww = sum(w);
    for e = 1:No_E
        w(e) = w(e)/sum_ww;
    end
    
    %% (3). Blum
    alpha = 1;    % Reward Constant
    beta = 1;    % Punishment Constant
    % (A).Weighted sum of each expert decision
    WS_LL(t) = 0;
    for e = 1:No_E
        WS_LL(t) = WS_LL(t) + (w(e)/sum(w)) * y_hat(t,e);
    end
    % (B). Decide The final action
    if (WS_LL(t) >= 0)
        final(t) = 1;   % Malignant
    else
        final(t) = -1;   % Benign
    end
    % (C). Update weights
    for e = 1:No_E
        % Update for every incorrect prediction
        if (y(t,e) ~= Train_Label(t))
            w(e) = w(e)*beta;    % Punish for Miss prediction
        else
            w(e) = w(e)*alpha;    % Reward for Correct prediction
        end
    end
    % (D). Normalized w after updating
    sum_ww = sum(w);
    for e = 1:No_E
        w(e) = w(e)/sum_ww;
    end
    
    %% (4). TrackExp
    alpha = 1;    % Reward Constant
    beta = 1;    % Punishment Constant
    
    % (A).Weighted sum of each expert decision
    WS_LL(t) = 0;
    for e = 1:No_E
        WS_LL(t) = WS_LL(t) + (w(e)/sum(w)) * y_hat(t,e);
    end
    % (B). Decide The final action
    if (WS_LL(t) >= 0)
        final(t) = 1;   % Malignant
    else
        final(t) = -1;   % Benign
    end
    
    % (C). Update weights
    for e = 1:No_E
        % Update for every incorrect prediction
        if (y(t,e) ~= Train_Label(t))
            w(e) = w(e)*beta + (alpha/(No_E-1)) * (sum(w)-w(e));    % Punish for Miss prediction
        else
            w(e) = w(e);    % Reward for Correct prediction
        end
    end
    
    % (D). Normalized w after updating
    sum_ww = sum(w);
    for e = 1:No_E
        w(e) = w(e)/sum_ww;
    end
    
    
end

