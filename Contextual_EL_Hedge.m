clear;
% %% % Generated by Jinsung Yoon (12th Oct 2015)
% % IUP + Contextual Hedge/Weighted Majority (Hedged Bandit)
% %% Data Input
% % Data (569 patients, 30 features, and 1 label)
% Data = csvread('Medical_Dataset.csv');
% 
% % Patient's Feature
% Feature = Data(:,1:30);
% % Patient's Label (Malignant = 1, Benign = 2)
% Label = Data(:,31);



% Feature Normalization
for i = 1:30
    Temp1 = max(Feature(:,i));
    Feature(:,i) = Feature(:,i)/Temp1;
end

%% System Variable
K = 10;     % Number of folds
T = 10000;      % Number of Timesteps
No_E = 3;       % Number of Experts
No_F_EL = 8;    % Number of EL features

% Parameters
% For CUP
m_t = 2;    % Number of adaptive partition of each feature
% Coefficient of the control function. Co*(t^(d_t))*log(t)
d_t = 0;
Co = 0.1;   

% For Hedge
kau = 0.5;    % Punishment Constant for Hedge

%% Fixed System Variable
[Patient_No Feature_No] = size(Feature);
Train_Rate = 0.5;
Train_No = ceil(Patient_No * Train_Rate);
Test_No = Patient_No - Train_No;
Action_No = 2;  % Malignant and Benign


%% Algorithm
% Iterative fold cross validation
for l = 1:K
    l
    %% Input Feature Randomization
    %% Train Data Randomize
    Train_Temp = datasample([1:Patient_No],Train_No);
    Train_Feature = Feature(Train_Temp,:);
    Train_Label = Label(Train_Temp);
    
    %% Test Data Randomize
    Test_Temp = setdiff([1:Patient_No],Train_Temp); % Excluding Train Data
    Test_Feature_Set = Feature(Test_Temp,:);
    Test_Label_Set = Label(Test_Temp);
    
    %% Test Data Generation (10,000 instances)
    for t = 1:T
        pat = round(Test_No*rand()+0.5);
        Test_Feature(t,:) = Test_Feature_Set(pat,:);
        Test_Label(t,:) = Test_Label_Set(pat);
    end
    
    %% Assigned features for each expert without overlapping
    Temp_Select=randperm(Feature_No);
    for e = 1:No_E
        F(e,:) = Temp_Select(((Feature_No/No_E)*e-((Feature_No/No_E)-1)):((Feature_No/No_E)*e));
    end
        
    %% Assigned features for EL
    F_EL=randperm(Feature_No,No_F_EL);
    
    
    %% Create Basic Matrix
    % For CUP
    S_T = zeros(No_E,m_t,m_t,m_t,m_t,m_t,m_t,m_t,m_t,m_t,m_t,Action_No);    % Sum of rewards for each partition
    N_T = zeros(No_E,m_t,m_t,m_t,m_t,m_t,m_t,m_t,m_t,m_t,m_t,Action_No);    % Number of patients in each partition
    R_T = zeros(No_E,m_t,m_t,m_t,m_t,m_t,m_t,m_t,m_t,m_t,m_t,Action_No);    % Sample Rewards for each partition
    
    % For Adaptive Partitioning
    S = zeros(Feature_No,2);    % Sum of feature values for Malignant and Benign patients
    R = zeros(Feature_No,2);    % Sample feature values for Malignant and Benign patients
    N = zeros(2,1);     % Number of Benign or Malignat patients
    P = zeros(Feature_No,1);    % Boundary of Adaptive Partitioning
        
    % Prediction of each expert
    y_hat = zeros(T,No_E);
    
    %% Initialization
    w = (1/(No_E))*ones(2,2,2,2,2,2,2,2,No_E);    % Weights of each experts
    final_y = zeros(T,1);    % Ensemble Learner Estimate 
    final = zeros(T,1);    % Ensemble Learner prediction
    
    % For Performance Evaluation
    Count = zeros(5,1);     % For ensemble learner
    Counting = zeros(5,No_E);   % For average, best and worst learner
        
    %% Training
    %% Adaptive Partitioning
    for i = 1:Train_No
        if (Train_Label(i) == 1)    % For Malignant
            N(1) = N(1) + 1;
            for f = 1:Feature_No
                S(f,1) = S(f,1) + Train_Feature(i,f);
                R(f,1) = S(f,1)/N(1);
            end
        else
            % For Benign
            N(2) = N(2) + 1;
            for f = 1:Feature_No
                S(f,2) = S(f,2) + Train_Feature(i,f);
                R(f,2) = S(f,2)/N(2);
            end
        end
        % Update the boundary of partition
        for f = 1:Feature_No
            P(f) = (R(f,1)+R(f,2))/2;
        end
    end
    
    
    for t = 1:Train_No
        % Exploitation/Exploration Flag for each Expert
        Flag = zeros(No_E,1);
        %% 1. Adaptive Partitioning
        for e = 1:No_E
            % Find P_T of X_T
            for k = 1:(Feature_No/No_E)
                if(Train_Feature(t,F(e,k)) < P(F(e,k)))     % The boundary is P(f), Updating Section is positioned at the end of the algorithm
                    x(t,F(e,k)) = 1;
                else
                    x(t,F(e,k)) = 2;
                end
            end
        end
        
        %% IUP Algorithm
        for e = 1:No_E
            % Exploitation
            if ((N_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),x(t,F(e,4)),x(t,F(e,5)),x(t,F(e,6)),x(t,F(e,7)),x(t,F(e,8)),x(t,F(e,9)),x(t,F(e,10)),1) > Co*(t^d_t)*log(t)) && (N_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),x(t,F(e,4)),x(t,F(e,5)),x(t,F(e,6)),x(t,F(e,7)),x(t,F(e,8)),x(t,F(e,9)),x(t,F(e,10)),2) > Co*(t^d_t)*log(t)))
                % Select the action which has higher estimated reward
                R_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),x(t,F(e,4)),x(t,F(e,5)),x(t,F(e,6)),x(t,F(e,7)),x(t,F(e,8)),x(t,F(e,9)),x(t,F(e,10)),1)=R_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),x(t,F(e,4)),x(t,F(e,5)),x(t,F(e,6)),x(t,F(e,7)),x(t,F(e,8)),x(t,F(e,9)),x(t,F(e,10)),1)*1;
                [Temp y_hat(t,e)] = max(R_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),x(t,F(e,4)),x(t,F(e,5)),x(t,F(e,6)),x(t,F(e,7)),x(t,F(e,8)),x(t,F(e,9)),x(t,F(e,10)),:));
                Flag(e) = 1;    % Meaning Exploitation
            else % Exploration
                % Flag initialization
                Flag1 = 0;  
                Flag2 = 0;
                % Flag Decision (To find which action needs exploration)
                if (N_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),x(t,F(e,4)),x(t,F(e,5)),x(t,F(e,6)),x(t,F(e,7)),x(t,F(e,8)),x(t,F(e,9)),x(t,F(e,10)),1) < Co*(t^d_t)*log(t))
                    Flag1 = 1;
                end
                if (N_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),x(t,F(e,4)),x(t,F(e,5)),x(t,F(e,6)),x(t,F(e,7)),x(t,F(e,8)),x(t,F(e,9)),x(t,F(e,10)),2) < Co*(t^d_t)*log(t))
                    Flag2 = 1;
                end
                % Action Selection
                if ((Flag1 == 1) && (Flag2 == 1))
                    y_hat(t,e) = round(rand())+1;        % If both actions need exploration, we randomly select one of them
                elseif (Flag1 == 1)
                    y_hat(t,e) = 1;
                else
                    y_hat(t,e) = 2;
                end
            end
            % y_hat(t,e) is the action that each expert selects
            
            % Update (Update estimated reward of the partition)
            for a = 1:Action_No
                S_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),x(t,F(e,4)),x(t,F(e,5)),x(t,F(e,6)),x(t,F(e,7)),x(t,F(e,8)),x(t,F(e,9)),x(t,F(e,10)),a) = S_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),x(t,F(e,4)),x(t,F(e,5)),x(t,F(e,6)),x(t,F(e,7)),x(t,F(e,8)),x(t,F(e,9)),x(t,F(e,10)),a) + (a==Train_Label(t));
                N_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),x(t,F(e,4)),x(t,F(e,5)),x(t,F(e,6)),x(t,F(e,7)),x(t,F(e,8)),x(t,F(e,9)),x(t,F(e,10)),a) = N_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),x(t,F(e,4)),x(t,F(e,5)),x(t,F(e,6)),x(t,F(e,7)),x(t,F(e,8)),x(t,F(e,9)),x(t,F(e,10)),a) + 1;
                R_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),x(t,F(e,4)),x(t,F(e,5)),x(t,F(e,6)),x(t,F(e,7)),x(t,F(e,8)),x(t,F(e,9)),x(t,F(e,10)),a) = S_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),x(t,F(e,4)),x(t,F(e,5)),x(t,F(e,6)),x(t,F(e,7)),x(t,F(e,8)),x(t,F(e,9)),x(t,F(e,10)),a)/N_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),x(t,F(e,4)),x(t,F(e,5)),x(t,F(e,6)),x(t,F(e,7)),x(t,F(e,8)),x(t,F(e,9)),x(t,F(e,10)),a);
            end
        end
        
         %% Hedge Algorithm
         
         % Update weights
         for e = 1:No_E
             if (Flag(e) == 1)   % Only for exploitation step expert
                 if (y_hat(t,e) ~= Train_Label(t))
                     w(x(t,F_EL(1)),x(t,F_EL(2)),x(t,F_EL(3)),x(t,F_EL(4)),x(t,F_EL(5)),x(t,F_EL(6)),x(t,F_EL(7)),x(t,F_EL(8)),e) = w(x(t,F_EL(1)),x(t,F_EL(2)),x(t,F_EL(3)),x(t,F_EL(4)),x(t,F_EL(5)),x(t,F_EL(6)),x(t,F_EL(7)),x(t,F_EL(8)),e)*kau;    % Punish for Miss prediction
                 end
             end
         end
         
         % Normalized w after updating
         sum_ww = sum(w(x(t,F_EL(1)),x(t,F_EL(2)),x(t,F_EL(3)),x(t,F_EL(4)),x(t,F_EL(5)),x(t,F_EL(6)),x(t,F_EL(7)),x(t,F_EL(8)),:));
         for e = 1:No_E
             w(x(t,F_EL(1)),x(t,F_EL(2)),x(t,F_EL(3)),x(t,F_EL(4)),x(t,F_EL(5)),x(t,F_EL(6)),x(t,F_EL(7)),x(t,F_EL(8)),e) = w(x(t,F_EL(1)),x(t,F_EL(2)),x(t,F_EL(3)),x(t,F_EL(4)),x(t,F_EL(5)),x(t,F_EL(6)),x(t,F_EL(7)),x(t,F_EL(8)),e)/sum_ww;
         end
         
                
    end
              
    %% Online Algorithm
    
    % Starting iteration for timestep
    for t = 1:T
        % Exploitation/Exploration Flag for each Expert
        Flag = zeros(No_E,1);
        %% 1. Adaptive Partitioning
        
        for e = 1:No_E
            % Find P_T of X_T
            for k = 1:(Feature_No/No_E)
                if(Test_Feature(t,F(e,k)) < P(F(e,k)))     % The boundary is P(f), Updating Section is positioned at the end of the algorithm
                    x(t,F(e,k)) = 1;
                else
                    x(t,F(e,k)) = 2;
                end
            end
        end
        
        %% IUP Algorithm
        for e = 1:No_E
            % Exploitation
            if ((N_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),x(t,F(e,4)),x(t,F(e,5)),x(t,F(e,6)),x(t,F(e,7)),x(t,F(e,8)),x(t,F(e,9)),x(t,F(e,10)),1) > Co*(t^d_t)*log(t)) && (N_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),x(t,F(e,4)),x(t,F(e,5)),x(t,F(e,6)),x(t,F(e,7)),x(t,F(e,8)),x(t,F(e,9)),x(t,F(e,10)),2) > Co*(t^d_t)*log(t)))
                % Select the action which has higher estimated reward
                R_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),x(t,F(e,4)),x(t,F(e,5)),x(t,F(e,6)),x(t,F(e,7)),x(t,F(e,8)),x(t,F(e,9)),x(t,F(e,10)),1)=R_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),x(t,F(e,4)),x(t,F(e,5)),x(t,F(e,6)),x(t,F(e,7)),x(t,F(e,8)),x(t,F(e,9)),x(t,F(e,10)),1)*1;
                [Temp y_hat(t,e)] = max(R_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),x(t,F(e,4)),x(t,F(e,5)),x(t,F(e,6)),x(t,F(e,7)),x(t,F(e,8)),x(t,F(e,9)),x(t,F(e,10)),:));
                Flag(e) = 1;    % Meaning Exploitation
            else % Exploration
                % Flag initialization
                Flag1 = 0;  
                Flag2 = 0;
                % Flag Decision (To find which action needs exploration)
                if (N_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),x(t,F(e,4)),x(t,F(e,5)),x(t,F(e,6)),x(t,F(e,7)),x(t,F(e,8)),x(t,F(e,9)),x(t,F(e,10)),1) < Co*(t^d_t)*log(t))
                    Flag1 = 1;
                end
                if (N_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),x(t,F(e,4)),x(t,F(e,5)),x(t,F(e,6)),x(t,F(e,7)),x(t,F(e,8)),x(t,F(e,9)),x(t,F(e,10)),2) < Co*(t^d_t)*log(t))
                    Flag2 = 1;
                end
                % Action Selection
                if ((Flag1 == 1) && (Flag2 == 1))
                    y_hat(t,e) = round(rand())+1;        % If both actions need exploration, we randomly select one of them
                elseif (Flag1 == 1)
                    y_hat(t,e) = 1;
                else
                    y_hat(t,e) = 2;
                end
            end
            % y_hat(t,e) is the action that each expert selects
            
            % Update (Update estimated reward of the partition)
            for a = 1:Action_No
                S_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),x(t,F(e,4)),x(t,F(e,5)),x(t,F(e,6)),x(t,F(e,7)),x(t,F(e,8)),x(t,F(e,9)),x(t,F(e,10)),a) = S_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),x(t,F(e,4)),x(t,F(e,5)),x(t,F(e,6)),x(t,F(e,7)),x(t,F(e,8)),x(t,F(e,9)),x(t,F(e,10)),a) + (a==Test_Label(t));
                N_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),x(t,F(e,4)),x(t,F(e,5)),x(t,F(e,6)),x(t,F(e,7)),x(t,F(e,8)),x(t,F(e,9)),x(t,F(e,10)),a) = N_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),x(t,F(e,4)),x(t,F(e,5)),x(t,F(e,6)),x(t,F(e,7)),x(t,F(e,8)),x(t,F(e,9)),x(t,F(e,10)),a) + 1;
                R_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),x(t,F(e,4)),x(t,F(e,5)),x(t,F(e,6)),x(t,F(e,7)),x(t,F(e,8)),x(t,F(e,9)),x(t,F(e,10)),a) = S_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),x(t,F(e,4)),x(t,F(e,5)),x(t,F(e,6)),x(t,F(e,7)),x(t,F(e,8)),x(t,F(e,9)),x(t,F(e,10)),a)/N_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),x(t,F(e,4)),x(t,F(e,5)),x(t,F(e,6)),x(t,F(e,7)),x(t,F(e,8)),x(t,F(e,9)),x(t,F(e,10)),a);
            end
        end
        
         %% Hedge Algorithm
        if (max(Flag) == 0) % Every Expert is in exploration step
            final(t) = y_hat(t,round(No_E*rand()+0.5));     % Randomly select the final action
        else
            % If any of experts is in exploitation step
            % Find experts in Exploitation step
            sum_w = 0;
            for e = 1:No_E
                if(Flag(e) == 1)
                    sum_w = sum_w + w(x(t,F_EL(1)),x(t,F_EL(2)),x(t,F_EL(3)),x(t,F_EL(4)),x(t,F_EL(5)),x(t,F_EL(6)),x(t,F_EL(7)),x(t,F_EL(8)),e);
                end
            end
            % Bar making for random selection
            for e = 1:No_E
                if (Flag(e) == 1)
                    w_bar(x(t,F_EL(1)),x(t,F_EL(2)),x(t,F_EL(3)),x(t,F_EL(4)),x(t,F_EL(5)),x(t,F_EL(6)),x(t,F_EL(7)),x(t,F_EL(8)),e) = w(x(t,F_EL(1)),x(t,F_EL(2)),x(t,F_EL(3)),x(t,F_EL(4)),x(t,F_EL(5)),x(t,F_EL(6)),x(t,F_EL(7)),x(t,F_EL(8)),e)/sum_w;
                else
                    w_bar(x(t,F_EL(1)),x(t,F_EL(2)),x(t,F_EL(3)),x(t,F_EL(4)),x(t,F_EL(5)),x(t,F_EL(6)),x(t,F_EL(7)),x(t,F_EL(8)),e) = 0;
                end
            end
            for e = 1:No_E
                if (e == 1)
                    bar(x(t,F_EL(1)),x(t,F_EL(2)),x(t,F_EL(3)),x(t,F_EL(4)),x(t,F_EL(5)),x(t,F_EL(6)),x(t,F_EL(7)),x(t,F_EL(8)),e) = w(x(t,F_EL(1)),x(t,F_EL(2)),x(t,F_EL(3)),x(t,F_EL(4)),x(t,F_EL(5)),x(t,F_EL(6)),x(t,F_EL(7)),x(t,F_EL(8)),e);
                else
                    bar(x(t,F_EL(1)),x(t,F_EL(2)),x(t,F_EL(3)),x(t,F_EL(4)),x(t,F_EL(5)),x(t,F_EL(6)),x(t,F_EL(7)),x(t,F_EL(8)),e) = bar(x(t,F_EL(1)),x(t,F_EL(2)),x(t,F_EL(3)),x(t,F_EL(4)),x(t,F_EL(5)),x(t,F_EL(6)),x(t,F_EL(7)),x(t,F_EL(8)),e-1)+w(x(t,F_EL(1)),x(t,F_EL(2)),x(t,F_EL(3)),x(t,F_EL(4)),x(t,F_EL(5)),x(t,F_EL(6)),x(t,F_EL(7)),x(t,F_EL(8)),e);
                end
            end
            
            % Make decision based on the bar
            Temp_Dec = rand();
            for e = 1:No_E
                if (e == 1)
                    if (Temp_Dec < bar(x(t,F_EL(1)),x(t,F_EL(2)),x(t,F_EL(3)),x(t,F_EL(4)),x(t,F_EL(5)),x(t,F_EL(6)),x(t,F_EL(7)),x(t,F_EL(8)),e))
                        final(t) = y_hat(t,e);
                    end
                else
                    if (Temp_Dec < bar(x(t,F_EL(1)),x(t,F_EL(2)),x(t,F_EL(3)),x(t,F_EL(4)),x(t,F_EL(5)),x(t,F_EL(6)),x(t,F_EL(7)),x(t,F_EL(8)),e)) && (Temp_Dec >= bar(x(t,F_EL(1)),x(t,F_EL(2)),x(t,F_EL(3)),x(t,F_EL(4)),x(t,F_EL(5)),x(t,F_EL(6)),x(t,F_EL(7)),x(t,F_EL(8)),e-1))
                        final(t) = y_hat(t,e);
                    end
                end
            end
                                     
            % Update weights
            for e = 1:No_E
                if (Flag(e) == 1)   % Only for exploitation step expert
                    if (y_hat(t,e) ~= Test_Label(t))
                        w(x(t,F_EL(1)),x(t,F_EL(2)),x(t,F_EL(3)),x(t,F_EL(4)),x(t,F_EL(5)),x(t,F_EL(6)),x(t,F_EL(7)),x(t,F_EL(8)),e) = w(x(t,F_EL(1)),x(t,F_EL(2)),x(t,F_EL(3)),x(t,F_EL(4)),x(t,F_EL(5)),x(t,F_EL(6)),x(t,F_EL(7)),x(t,F_EL(8)),e)*kau;    % Punish for Miss prediction
                    end
                end
            end
            
            % Normalized w after updating
            sum_ww = sum(w(x(t,F_EL(1)),x(t,F_EL(2)),x(t,F_EL(3)),x(t,F_EL(4)),x(t,F_EL(5)),x(t,F_EL(6)),x(t,F_EL(7)),x(t,F_EL(8)),:));
            for e = 1:No_E
                w(x(t,F_EL(1)),x(t,F_EL(2)),x(t,F_EL(3)),x(t,F_EL(4)),x(t,F_EL(5)),x(t,F_EL(6)),x(t,F_EL(7)),x(t,F_EL(8)),e) = w(x(t,F_EL(1)),x(t,F_EL(2)),x(t,F_EL(3)),x(t,F_EL(4)),x(t,F_EL(5)),x(t,F_EL(6)),x(t,F_EL(7)),x(t,F_EL(8)),e)/sum_ww;
            end
           
       end
%        
        
        %% Adaptive Partitioning Updating
        if (Test_Label(t) == 1)    % For Malignant
            N(1) = N(1) + 1;    
            for f = 1:Feature_No
                S(f,1) = S(f,1) + Test_Feature(t,f);
                R(f,1) = S(f,1)/N(1);
            end
        else
            % For Benign
            N(2) = N(2) + 1;
            for f = 1:Feature_No
                S(f,2) = S(f,2) + Test_Feature(t,f);
                R(f,2) = S(f,2)/N(2);
            end
        end  
        % Update the boundary of partition
        for f = 1:Feature_No
            P(f) = (R(f,1)+R(f,2))/2;
        end
                
        %% Performance Analysis
        % For PER
        if (Test_Label(t) ~= final(t))
            Count(1) = Count(1) + 1;
        end
        % For FAR
        if ((Test_Label(t) == 2) && (final(t) == 1))
            Count(2) = Count(2) + 1;
        end
        % For MDR
        if ((Test_Label(t) == 1) && (final(t) == 2))
            Count(3) = Count(3) + 1;
        end
        if (Test_Label(t) == 2)
            % For FAR
            Count(4) = Count(4) + 1;
        else
            % For MDR
            Count(5) = Count(5) + 1;
        end
      
        
        %% Performance Analysis for Each Expert
        for e = 1:No_E
            % For PER
            if (Test_Label(t) ~= y_hat(t,e))
                Counting(1,e) = Counting(1,e) + 1;
            end
            % For FAR
            if ((Test_Label(t) == 2) && ( y_hat(t,e) == 1))
                Counting(2,e) = Counting(2,e) + 1;
            end
            % For MDR
            if ((Test_Label(t) == 1) && ( y_hat(t,e) == 2))
                Counting(3,e) = Counting(3,e) + 1;
            end
            if (Test_Label(t) == 2)
                % For FAR
                Counting(4,e) = Counting(4,e) + 1;
            else
                % For MDR
                Counting(5,e) = Counting(5,e) + 1;
            end
        end
                
       
    end
    %% Print Out the Performance of Hedged bandit
    Prob_Err(l) = Count(1)/(T);
    False_Alarm(l) = Count(2)/(Count(2)+Count(4));
    Miss_Detection(l) = Count(3)/(Count(3) + Count(5));
    
    %% Print Out the performance of Best, Worst and Average Expert
 
    for e = 1:No_E
        Prob_Err_Exp(l,e) = Counting(1,e)/(T);
    end
    % For the Best Expert
    [Temp B_E] = min(Prob_Err_Exp(l,:));
    Best_PE(l) = Counting(1,B_E)/T;
    Best_FA(l) = Counting(2,B_E)/( Counting(2,B_E) + Counting(4,B_E));
    Best_MD(l) = Counting(3,B_E)/( Counting(3,B_E) + Counting(5,B_E));
    
    % For the Worst Expert
    [Temp W_E] = max(Prob_Err_Exp(l,:));
    Worst_PE(l) = Counting(1,W_E)/T;
    Worst_FA(l) = Counting(2,W_E)/( Counting(2,W_E) + Counting(4,W_E));
    Worst_MD(l) = Counting(3,W_E)/( Counting(3,W_E) + Counting(5,W_E)); 
    
    % For the Average Expert
    Avg_PE(l) = sum(Counting(1,:))/(No_E*T);
    Avg_FA(l) = sum(Counting(2,:))/( sum(Counting(2,:)) + sum(Counting(4,:)));
    Avg_MD(l) = sum(Counting(3,:))/( sum(Counting(3,:)) + sum(Counting(5,:))); 
    
end

%% Printing Result of Cross Validation

% Result of Weighted Majority
Result(1,1) = mean(Prob_Err);
Result(2,1) = mean(False_Alarm);
Result(3,1) = mean(Miss_Detection);

Result(4,1) = std(Prob_Err);
Result(5,1) = std(False_Alarm);
Result(6,1) = std(Miss_Detection);

% Result of Best Learner
Result(1,2) = mean(Best_PE);
Result(2,2) = mean(Best_FA);
Result(3,2) = mean(Best_MD);

Result(4,2) = std(Best_PE);
Result(5,2) = std(Best_FA);
Result(6,2) = std(Best_MD);

% Result of Worst Learner
Result(1,3) = mean(Worst_PE);
Result(2,3) = mean(Worst_FA);
Result(3,3) = mean(Worst_MD);

Result(4,3) = std(Worst_PE);
Result(5,3) = std(Worst_FA);
Result(6,3) = std(Worst_MD);

% Result of Average Learner
Result(1,4) = mean(Avg_PE);
Result(2,4) = mean(Avg_FA);
Result(3,4) = mean(Avg_MD);

Result(4,4) = std(Avg_PE);
Result(5,4) = std(Avg_FA);
Result(6,4) = std(Avg_MD);
