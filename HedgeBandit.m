clear;
%% % Generated by Jinsung Yoon (8/11/2016)
% Hedge Bandit

%% 1. Data Input
%load('Data.mat');
raw_data=importdata('wdbc.data.txt');
norm=max(raw_data(:,3:end));
Input_Feature=zeros(size(raw_data(:,3:end)));
for i=1:size(Input_Feature,1),
Input_Feature(i,:)=raw_data(i,3:end)./norm;
end
Input_Label=raw_data(:,2)+1;
% Input_Feature, Input_Label

%% 2. System Variable
% General Parameters
[T, Feature_No] = size(Input_Feature);      % Number of Instances
%T=10000;
%M = 10;       % Number of Local Learner
M = 3 ;       %

% Algorithm Parameters
% For IUP
m_i = 2;    % Number of partition on each feature
d_i = Feature_No/M;     % Number of features assinged to each Local Learner
F_i = 2;        % Number of hypothesis

% Fixed Variable
alpha_fix = 2 * ( 1 + 2* log( 2 * abs(F_i) * (m_i)^(d_i) * T^(1.5) ) );

%% 3. Algorithm

%% 3.1 Assigned features for each expert without overlapping
Temp_Select=randperm(Feature_No);
for e = 1:M
    F(e,:) = Temp_Select(((Feature_No/M)*e-((Feature_No/M)-1)):((Feature_No/M)*e));
end

%% 3.2 Initialization
%% Create Basic Matrix
% For IUP
S_T = zeros(M,m_i,m_i,m_i,F_i);    % Sum of rewards for each partition
N_T = zeros(M,m_i,m_i,m_i,F_i);    % Number of patients in each partition
R_T = zeros(M,m_i,m_i,m_i,F_i);    % Sample mean of Rewards for each partition

% Prediction of each expert
y_hat = zeros(T,M);

% For Ensemble Learner
w = (1/(M))*ones(M,1);    % Weights of each experts
final_y = zeros(T,1);    % Ensemble Learner Estimation
final = zeros(T,1);    % Ensemble Learner prediction

%% 3.3 Online Algorithm

% % base learner is replaced by logistic regression
% %cv 10 fold
% cvind=crossvalind('Kfold',size(Input_Feature,1),2);
% %decentralized
% featde=crossvalind('Kfold',size(Input_Feature,2),3);
% 
% %create base classifier score
% numcla=3;
% prd=zeros(numcla,length(find(cvind==1)));% total target,C{3}
% sp=categorical(Input_Label);
% 
% for i=1:numcla,
%     %linear regression
% %     mdl{i}=fitlm(Input_Feature(cvind~=i,:), Input_Label(cvind~=i));
% %     prd_L{i}=predict(mdl{i}, Input_Feature)';
% %     prd(i,prd_L{i}>1.5)=2;
%     %linear regression
%      B=fitlm(Input_Feature(cvind~=1,featde==i),Input_Label(cvind~=1));%train by cv=2
%      predpool=find(cvind==1);
%      predind=randi(length(predpool),1,T);
%      y_hat_tmp{i}=predict(B,Input_Feature(predpool(predind),featde==i)); %perdict cv=1, drawn T
% %     %logistic regression
% %     B=mnrfit(Input_Feature(cvind~=1,featde==i),sp(cvind~=1));%train by cv=2
% %     predpool=find(cvind==1);
% %     predind=randi(length(predpool),1,T);
% %     y_hat_tmp{i}=mnrval(B,Input_Feature(predpool(predind),featde==i)); %perdict cv=1, drawn T
%     
% end


for hyper=1:100,
    
%     for i=1:numcla,
%         y_hat(y_hat_tmp{i}>=1+0.01*(hyper),i)=2;
%         y_hat(y_hat_tmp{i}<1+0.01*(hyper),i)=1;
%     end
for t = 1:T
    
    %% A. Uniform Partitioning
    for f = 1:Feature_No
        for j = 1:m_i
            if(Input_Feature(t,f) >= (j-1)/m_i) && (Input_Feature(t,f) < j/m_i)
                x(t,f) = j;
            elseif (Input_Feature(t,f) == 1)
                x(t,f) = m_i;
            end
        end
    end
    
    %% B. IUP Algorithm
    for e = 1:M
        Temp1(e,1) = N_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),1);
        Temp2(e,1) = R_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),1);
%         Index(e,1) = Temp2(e,1) + sqrt(alpha_fix/Temp1(e,1));
        Index(e,1) = hyper/20*( Temp2(e,1) + sqrt(alpha_fix/Temp1(e,1)));
        
        Temp1(e,2) = N_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),2);
        Temp2(e,2) = R_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),2);
        Index(e,2) = Temp2(e,2) + sqrt(alpha_fix/Temp1(e,2));
        
        if(Temp1(e,1) == 0)
            y_hat(t,e) = 1;
        elseif (Temp1(e,2) == 0)
            y_hat(t,e) = 2;
        else
            [Temp y_hat(t,e)] = max(Index(e,:));
        end
        % y_hat(t,e) is the action that each expert selects
        
        % Update (Update estimated reward of the partition)
        S_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),y_hat(t,e)) = S_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),y_hat(t,e)) + (y_hat(t,e)==Input_Label(t));
        N_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),y_hat(t,e)) = N_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),y_hat(t,e)) + 1;
        R_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),y_hat(t,e)) = S_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),y_hat(t,e))/N_T(e,x(t,F(e,1)),x(t,F(e,2)),x(t,F(e,3)),y_hat(t,e));
    end
    
    %% Anytime Hedge    
    for e = 1:M
        %L(t,e) = t-sum(y_hat(1:t,e)==Input_Label(predpool(predind(1:t))));
        L(t,e) = t-sum(y_hat(1:t,e)==Input_Label(1:t));

    end
    eta = sqrt(log(M)/t);
    
    for e = 1:M
        w(e) = exp(-(eta * L(t,e)))/(exp(-(eta*L(t,1)))+exp(-(eta*L(t,2)))+exp(-(eta*L(t,3))));
    end
    
    sum_w = sum(w);
    
    for e = 1:M
        w_bar(e) = w(e)/sum_w;
    end
    
    for e = 1:M
        if (e == 1)
            bar(e) = w_bar(e);
        else
            bar(e) = bar(e-1)+w_bar(e);
        end
    end
    
    % Make decision based on the bar
    Temp_Dec = rand();
    for e = 1:M
        if (e == 1)
            if (Temp_Dec < bar(e))
                final(t) = y_hat(t,e);
            end
        else
            if (Temp_Dec < bar(e)) && (Temp_Dec >= bar(e-1))
                final(t) = y_hat(t,e);
            end
        end
    end
    
end
[c,cm,ind,per] =confusion((Input_Label-1)',(final-1)');
cerr(hyper)=c;
TPR(hyper)=cm(2,2)/(sum(cm(2,:)));
FPR(hyper)=cm(1,2)/sum(cm(1,:));
if TPR(hyper)<0.97,
    c
end
end

